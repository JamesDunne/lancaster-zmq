LanCaster - Multiple-client file transfer protocol for LANs

(C)opyright 2011 James S. Dunne, lancaster@bittwiddlers.org

What is it?
-----------
LanCaster is a pair of console tools for sending folders to multiple subscribed clients. These tools use ZeroMQ (www.zeromq.org) for data transfer. The server process is named LCS (LanCaster Server) and acts as a publisher of file data to subscribers. The client process is named LCC (LanCaster Client) and subscribes to the publisher and gets the listing of files and downloads the chunks of data broadcast to a local folder, creating the files as it goes.

NOTES
-----
The client LCC stores a local state-tracking folder in the download folder named '.lcc'. This simply keeps track of which chunks of the transfer have been received and which have not in case of an early termination of the client. When the transfer completes successfully, the folder is deleted so as to not dirty the download.

TUNING PARAMETERS
-----------------
The LCS server gives you a couple of options to tune in order to gain performance. The -c <chunk size> should be set to something reasonably large like 1048576 (1 MB) or possibly larger, but I wouldn't go too high unless you think your network can handle very large sustained packet transfer. As a general guideline, I wouldn't recommend setting it any higher than 8388608 (8MB).

The -w <high water mark> is how many chunks of the specified chunk size (-c option) are queued up into memory to write to/read from the network. Large values upwards of 256 can help your application handle more network throughput, trading memory for time. If you feel you can dedicate 1GB or more of memory, try using higher -w values like 1024. In general, multiply the -w value by the -c value for a reasonable expected maximum amount of memory to be allocated.

The LCC client supports a -k <high water mark> argument used to set the disk writer queue's high water mark. The client pulls down chunks from the network as fast as it can until it reaches its network HWM (or until memory is exhausted if network HWM is zero - in which case the program dies) and immediately queues the chunks onto the disk writer's queue. If when pushing to the disk writer's queue its HWM is reached, the client will block (wait) until the disk writer thread catches up with its queue and writes the existing queued chunks to disk. Having the main client thread block will cause its network HWM to be reached since the thread is busy waiting for the disk writer to complete. In this scenario, network chunks will be dropped, so setting a disk HWM as high as possible will be ideal for optimal network throughput. With this design, slower clients will not slow down faster clients.

TODO
----
Switch from TCP to EPGM protocol for multicast network efficiency. The Windows build of libzmq does not include EPGM support by default, and doing so does not look simple nor easy at the moment.
GUI tools for client and server once protocol is stabilized and proven, and once EPGM is implemented and thoroughly tested.
Possibly SHA1 hash verification per file, but hash mismatches between client/server would only indicate presence of bugs in the client/server code. ZeroMQ guarantees complete message delivery or no message at all. I doubt there'd be any data loss to warrant such SHA1 hash calculations.
Packaging of transfers into uniquely-identifiable objects, much like a torrent. This would help clients uniquely identify a transfer, which transfers have completed.
A daemon mode for the client to auto-accept transfers and download them to known locations - ideal for server farm deployments.

TROUBLESHOOTING
---------------
You must install the Microsoft C++ 2010 (x86) redistributable (http://www.microsoft.com/downloads/en/details.aspx?FamilyID=a7b7a05e-6de6-4d3a-a423-37bf0912db84) in order for this tool to work. If you do not, you will get a message like System.DllNotFoundException: Unable to load DLL 'libzmq': The specified module could not be found. (Exception from HRESULT: 0x8007007E).
